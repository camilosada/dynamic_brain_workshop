{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f6ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports \n",
    "import os \n",
    "import sys\n",
    "import logging\n",
    "import platform\n",
    "from os.path import join as pjoin\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats \n",
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "# Pynwb imports\n",
    "from hdmf_zarr import NWBZarrIO\n",
    "from nwbwidgets import nwb2widget\n",
    "\n",
    "sys.path.insert(0,'/code/src')\n",
    "from bci.loaders import load\n",
    "from bci.thresholds.thresholds import align_thresholds\n",
    "from bci.trials.align import indep_roll\n",
    "from bci.dataviz import traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab7d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(message)s \",\n",
    "    datefmt=\"%d/%m/%Y %I:%M:%S %p\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6d7eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data directory set to /data/\n"
     ]
    }
   ],
   "source": [
    "# set data path\n",
    "platstring = platform.platform()\n",
    "system = platform.system()\n",
    "if system == \"Darwin\":\n",
    "    # macOS\n",
    "    data_dir = \"/Volumes/Brain2025/\"\n",
    "elif system == \"Windows\":\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_dir = \"E:/\"\n",
    "elif \"amzn\" in platstring:\n",
    "    # then on CodeOcean\n",
    "    data_dir = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_dir = \"/media/$USERNAME/Brain2025/\"\n",
    "    \n",
    "print('data directory set to', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67d7522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected subject is 772414\n",
      "Selected session is single-plane-ophys_772414_2025-02-10_11-15-26_processed_2025-08-04_23-06-21\n"
     ]
    }
   ],
   "source": [
    "# Load metadata csv file\n",
    "metadata = pd.read_csv(os.path.join(data_dir, 'bci_task_metadata', 'bci_metadata.csv'))\n",
    "# Get all mice available\n",
    "subject_ids = np.sort(metadata['subject_id'].unique())\n",
    "# Select one mice\n",
    "n_subjects = len(subject_ids)\n",
    "subject_id = 772414#subject_ids[1]#754303\n",
    "# Select one subject metadata, sorted by 'session_number'\n",
    "this_mouse_metadata = metadata[metadata['subject_id']==subject_id].sort_values(by='session_number')\n",
    "# Pick one session for this mouse\n",
    "session_name = this_mouse_metadata.name.values[3]\n",
    "print('Selected subject is', subject_id)\n",
    "print('Selected session is', session_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c24af9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCI data directory: /data/brain-computer-interface\n",
      "\n",
      "Session directory: /data/brain-computer-interface/single-plane-ophys_772414_2025-02-10_11-15-26_processed_2025-08-04_23-06-21\n",
      "\n",
      "NWB file: single-plane-ophys_772414_2025-02-10_11-15-26_behavior_nwb\n",
      "NWB path: /data/brain-computer-interface/single-plane-ophys_772414_2025-02-10_11-15-26_processed_2025-08-04_23-06-21/single-plane-ophys_772414_2025-02-10_11-15-26_behavior_nwb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/hdmf/spec/namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.7.0 because version 2.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All threshold files for mouse 772414: ['single-plane-ophys_772414_2025-02-10', 'single-plane-ophys_772414_2025-02-06', 'single-plane-ophys_772414_2025-01-27']\n",
      "\n",
      "Found threshold file at: /data/bci-thresholds/single-plane-ophys_772414_2025-02-10\n"
     ]
    }
   ],
   "source": [
    "# Read data in nwb file\n",
    "nwbfile = load.load_nwb_session_file(session_name)\n",
    "epoch_table = nwbfile.intervals[\"epochs\"].to_dataframe()\n",
    "dff_traces = nwbfile.processing[\"processed\"].data_interfaces[\"dff\"].roi_response_series[\"dff\"].data\n",
    "roi_table = nwbfile.processing[\"processed\"].data_interfaces[\"image_segmentation\"].plane_segmentations[\"roi_table\"].to_dataframe()\n",
    "frame_rate = nwbfile.imaging_planes[\"processed\"].imaging_rate\n",
    "bci_trials = nwbfile.stimulus[\"Trials\"].to_dataframe()\n",
    "thresholds = load.load_session_thresh_file(session_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a198d48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total difference in dataframes: 3\n"
     ]
    }
   ],
   "source": [
    "# Add threshold information to the trials\n",
    "bci_trials = align_thresholds(bci_trials=bci_trials, thresholds=thresholds)\n",
    "# Get correct trials\n",
    "correct_bci_trials = bci_trials[bci_trials['hit']==True]\n",
    "# Select trials where there is information about threshold\n",
    "correct_bci_trials = correct_bci_trials[correct_bci_trials['low'].notna()]\n",
    "correct_bci_trials.dropna(inplace=True,subset=['start_time', 'stop_time','threshold_crossing_times'])\n",
    "correct_bci_trials=correct_bci_trials.reset_index()\n",
    "\n",
    "# select relevant information\n",
    "BCI_epochs = epoch_table[epoch_table.stimulus_name.str.contains('BCI')]\n",
    "start_bci_epoch = BCI_epochs.loc[BCI_epochs.index[0]].start_frame\n",
    "stop_bci_epoch = BCI_epochs.loc[BCI_epochs.index[0]].stop_frame\n",
    "start_bci_trial = correct_bci_trials['start_frame']-start_bci_epoch\n",
    "stop_bci_trial = correct_bci_trials['stop_frame']-start_bci_epoch\n",
    "thrcrossframe_bci_trial = np.round(correct_bci_trials['threshold_crossing_times']*frame_rate).astype(int)\n",
    "zaber_steps = np.round(np.array(correct_bci_trials['zaber_step_times'].tolist())*frame_rate)\n",
    "go_cue_bci = np.round(correct_bci_trials['go_cue']*frame_rate).astype(int)\n",
    "reward_time = np.round(correct_bci_trials['reward_time']*frame_rate).astype(int)\n",
    "\n",
    "low_thres =correct_bci_trials.low\n",
    "high_thres =correct_bci_trials.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35f50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN: [1075]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Select relevant epoch\n",
    "dff_bci = dff_traces[start_bci_epoch:stop_bci_epoch, :]\n",
    "dff_bci = dff_bci.T# Transpose so rows are ROI IDs\n",
    "\n",
    "# Remove ROIs with traces that are NaNs (note - this takes a few seconds)\n",
    "valid_trace_ids = [i for i in range(dff_traces.shape[1]) if np.isnan(dff_traces[0, i])==False]\n",
    "# Limit ROI table to non-NaN traces\n",
    "roi_table2 = roi_table.loc[valid_trace_ids]\n",
    "\n",
    "# Find the likely somatic ROIs\n",
    "soma_probability = 0.005 # Emperically determined threshold - just trust us\n",
    "# Limit to valid somatic ROIs\n",
    "valid_rois = roi_table2[roi_table2.soma_probability>soma_probability]\n",
    "target_roi_idx = bci_trials['closest_roi'].unique()\n",
    "print(f\"CN: {target_roi_idx}\")\n",
    "if len(target_roi_idx)>1:\n",
    "    raise ValueError(\"More than one CN during BCI epoch\")\n",
    "target_roi_idx=target_roi_idx[0]\n",
    "if not(target_roi_idx in valid_rois.index):\n",
    "    valid_rois = pd.concat((valid_rois, roi_table2.loc[[target_roi_idx], :]), axis=0)\n",
    "    valid_rois = valid_rois.sort_index()\n",
    "\n",
    "# Select valid rois\n",
    "dff_bci_valid = dff_bci[valid_rois.index.values, :]\n",
    "roi_original_idx = valid_rois.reset_index()['id']\n",
    "#cn_new_idx = roi_original_idx[roi_original_idx==target_roi_idx].index[0]\n",
    "\n",
    "# Smooth dff\n",
    "smoothing_window = 10\n",
    "smooth_dff_valid = np.full(dff_bci_valid.shape,np.nan)\n",
    "kernel = np.ones(smoothing_window) / smoothing_window\n",
    "for itr,trial in enumerate (dff_bci_valid):\n",
    "    smooth_dff_valid[itr] = np.convolve(trial, kernel, mode='same')\n",
    "\n",
    "# Organize data by trials\n",
    "n_rois = smooth_dff_valid.shape[0]\n",
    "n_trials = len(start_bci_trial)\n",
    "max_tr_duration = np.max(stop_bci_trial-start_bci_trial)\n",
    "dff_by_trial = np.full((n_rois,n_trials,max_tr_duration*2),np.nan)\n",
    "for itr,(ist,istp) in enumerate(zip(start_bci_trial,stop_bci_trial)):\n",
    "\n",
    "    dff_by_trial[:,itr,:int(istp-ist)] = smooth_dff_valid[:,ist:istp]\n",
    "\n",
    "# Let's align on threshold_crossing_times\n",
    "frames_before = int(np.max(thrcrossframe_bci_trial.values))\n",
    "shifts = thrcrossframe_bci_trial.values -frames_before\n",
    "dff_bci_alignon_thr = indep_roll(dff_by_trial,-shifts,axis=-1)\n",
    "\n",
    "# get when the threshold changes\n",
    "idx_threshold_change = np.insert(np.where(np.insert(np.diff(high_thres), 0, 0)),0,0)\n",
    "idx_threshold_change=np.append(idx_threshold_change,n_trials)\n",
    "# idx_threshold_change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5992b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e24bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/09/2025 03:30:47 AM | 0 \n",
      "02/09/2025 03:30:48 AM | 1 \n",
      "02/09/2025 03:30:48 AM | 2 \n",
      "02/09/2025 03:30:48 AM | 3 \n",
      "02/09/2025 03:30:49 AM | 4 \n",
      "02/09/2025 03:30:49 AM | 5 \n",
      "02/09/2025 03:30:49 AM | 6 \n",
      "02/09/2025 03:30:50 AM | 7 \n",
      "02/09/2025 03:30:50 AM | 8 \n",
      "02/09/2025 03:30:50 AM | 9 \n",
      "02/09/2025 03:30:51 AM | 10 \n",
      "02/09/2025 03:30:51 AM | 11 \n",
      "02/09/2025 03:30:51 AM | 12 \n",
      "02/09/2025 03:30:52 AM | 13 \n",
      "02/09/2025 03:30:52 AM | 14 \n",
      "02/09/2025 03:30:52 AM | 15 \n",
      "02/09/2025 03:30:53 AM | 16 \n",
      "02/09/2025 03:30:53 AM | 17 \n",
      "02/09/2025 03:30:53 AM | 18 \n",
      "02/09/2025 03:30:54 AM | 19 \n",
      "02/09/2025 03:30:54 AM | 20 \n",
      "02/09/2025 03:30:54 AM | 21 \n",
      "02/09/2025 03:30:55 AM | 22 \n",
      "02/09/2025 03:30:55 AM | 23 \n",
      "02/09/2025 03:30:55 AM | 24 \n",
      "02/09/2025 03:30:56 AM | 25 \n",
      "02/09/2025 03:30:56 AM | 26 \n",
      "02/09/2025 03:30:56 AM | 27 \n",
      "02/09/2025 03:30:57 AM | 28 \n",
      "02/09/2025 03:30:57 AM | 29 \n",
      "02/09/2025 03:30:57 AM | 30 \n",
      "02/09/2025 03:30:58 AM | 31 \n",
      "02/09/2025 03:30:58 AM | 32 \n",
      "02/09/2025 03:30:58 AM | 33 \n",
      "02/09/2025 03:30:59 AM | 34 \n",
      "02/09/2025 03:30:59 AM | 35 \n",
      "02/09/2025 03:31:00 AM | 36 \n",
      "02/09/2025 03:31:00 AM | 37 \n",
      "02/09/2025 03:31:00 AM | 38 \n",
      "02/09/2025 03:31:00 AM | 39 \n",
      "02/09/2025 03:31:01 AM | 40 \n",
      "02/09/2025 03:31:01 AM | 41 \n",
      "02/09/2025 03:31:01 AM | 42 \n",
      "02/09/2025 03:31:02 AM | 43 \n",
      "02/09/2025 03:31:02 AM | 44 \n",
      "02/09/2025 03:31:02 AM | 45 \n",
      "02/09/2025 03:31:03 AM | 46 \n",
      "02/09/2025 03:31:03 AM | 47 \n",
      "02/09/2025 03:31:03 AM | 48 \n",
      "02/09/2025 03:31:04 AM | 49 \n",
      "02/09/2025 03:31:04 AM | 50 \n",
      "02/09/2025 03:31:04 AM | 51 \n",
      "02/09/2025 03:31:04 AM | 52 \n",
      "02/09/2025 03:31:05 AM | 53 \n",
      "02/09/2025 03:31:05 AM | 54 \n",
      "02/09/2025 03:31:06 AM | 55 \n",
      "02/09/2025 03:31:06 AM | 56 \n",
      "02/09/2025 03:31:06 AM | 57 \n",
      "02/09/2025 03:31:07 AM | 58 \n",
      "02/09/2025 03:31:07 AM | 59 \n",
      "02/09/2025 03:31:07 AM | 60 \n",
      "02/09/2025 03:31:08 AM | 61 \n",
      "02/09/2025 03:31:08 AM | 62 \n",
      "02/09/2025 03:31:08 AM | 63 \n",
      "02/09/2025 03:31:09 AM | 64 \n",
      "02/09/2025 03:31:09 AM | 65 \n",
      "02/09/2025 03:31:09 AM | 66 \n",
      "02/09/2025 03:31:09 AM | 67 \n",
      "02/09/2025 03:31:10 AM | 68 \n",
      "02/09/2025 03:31:10 AM | 69 \n",
      "02/09/2025 03:31:10 AM | 70 \n",
      "02/09/2025 03:31:11 AM | 71 \n",
      "02/09/2025 03:31:11 AM | 72 \n",
      "02/09/2025 03:31:11 AM | 73 \n",
      "02/09/2025 03:31:12 AM | 74 \n",
      "02/09/2025 03:31:12 AM | 75 \n",
      "02/09/2025 03:31:12 AM | 76 \n",
      "02/09/2025 03:31:13 AM | 77 \n",
      "02/09/2025 03:31:13 AM | 78 \n",
      "02/09/2025 03:31:14 AM | 79 \n",
      "02/09/2025 03:31:14 AM | 80 \n",
      "02/09/2025 03:31:14 AM | 81 \n",
      "02/09/2025 03:31:15 AM | 82 \n",
      "02/09/2025 03:31:15 AM | 83 \n",
      "02/09/2025 03:31:15 AM | 84 \n",
      "02/09/2025 03:31:15 AM | 85 \n",
      "02/09/2025 03:31:16 AM | 86 \n",
      "02/09/2025 03:31:16 AM | 87 \n",
      "02/09/2025 03:31:16 AM | 88 \n",
      "02/09/2025 03:31:17 AM | 89 \n",
      "02/09/2025 03:31:17 AM | 90 \n",
      "02/09/2025 03:31:17 AM | 91 \n",
      "02/09/2025 03:31:18 AM | 92 \n",
      "02/09/2025 03:31:18 AM | 93 \n",
      "02/09/2025 03:31:18 AM | 94 \n",
      "02/09/2025 03:31:19 AM | 95 \n",
      "02/09/2025 03:31:19 AM | 96 \n",
      "02/09/2025 03:31:19 AM | 97 \n",
      "02/09/2025 03:31:20 AM | 98 \n",
      "02/09/2025 03:31:20 AM | 99 \n",
      "02/09/2025 03:31:20 AM | 100 \n",
      "02/09/2025 03:31:21 AM | 101 \n",
      "02/09/2025 03:31:21 AM | 102 \n",
      "02/09/2025 03:31:21 AM | 103 \n",
      "02/09/2025 03:31:22 AM | 104 \n",
      "02/09/2025 03:31:22 AM | 105 \n",
      "02/09/2025 03:31:22 AM | 106 \n",
      "02/09/2025 03:31:22 AM | 107 \n",
      "02/09/2025 03:31:23 AM | 108 \n",
      "02/09/2025 03:31:24 AM | 109 \n",
      "02/09/2025 03:31:24 AM | 110 \n",
      "02/09/2025 03:31:24 AM | 111 \n",
      "02/09/2025 03:31:25 AM | 112 \n",
      "02/09/2025 03:31:25 AM | 113 \n",
      "02/09/2025 03:31:25 AM | 114 \n",
      "02/09/2025 03:31:25 AM | 115 \n",
      "02/09/2025 03:31:26 AM | 116 \n",
      "02/09/2025 03:31:26 AM | 117 \n",
      "02/09/2025 03:31:26 AM | 118 \n",
      "02/09/2025 03:31:27 AM | 119 \n",
      "02/09/2025 03:31:27 AM | 120 \n",
      "02/09/2025 03:31:27 AM | 121 \n",
      "02/09/2025 03:31:28 AM | 122 \n",
      "02/09/2025 03:31:28 AM | 123 \n",
      "02/09/2025 03:31:28 AM | 124 \n",
      "02/09/2025 03:31:29 AM | 125 \n",
      "02/09/2025 03:31:29 AM | 126 \n",
      "02/09/2025 03:31:29 AM | 127 \n",
      "02/09/2025 03:31:30 AM | 128 \n",
      "02/09/2025 03:31:30 AM | 129 \n",
      "02/09/2025 03:31:30 AM | 130 \n",
      "02/09/2025 03:31:31 AM | 131 \n",
      "02/09/2025 03:31:31 AM | 132 \n",
      "02/09/2025 03:31:31 AM | 133 \n",
      "02/09/2025 03:31:32 AM | 134 \n",
      "02/09/2025 03:31:32 AM | 135 \n",
      "02/09/2025 03:31:32 AM | 136 \n",
      "02/09/2025 03:31:32 AM | 137 \n",
      "02/09/2025 03:31:33 AM | 138 \n",
      "02/09/2025 03:31:33 AM | 139 \n",
      "02/09/2025 03:31:33 AM | 140 \n",
      "02/09/2025 03:31:34 AM | 141 \n",
      "02/09/2025 03:31:34 AM | 142 \n",
      "02/09/2025 03:31:34 AM | 143 \n",
      "02/09/2025 03:31:35 AM | 144 \n",
      "02/09/2025 03:31:36 AM | 145 \n",
      "02/09/2025 03:31:36 AM | 146 \n",
      "02/09/2025 03:31:36 AM | 147 \n",
      "02/09/2025 03:31:37 AM | 148 \n",
      "02/09/2025 03:31:37 AM | 149 \n",
      "02/09/2025 03:31:37 AM | 150 \n",
      "02/09/2025 03:31:38 AM | 151 \n",
      "02/09/2025 03:31:38 AM | 152 \n",
      "02/09/2025 03:31:38 AM | 153 \n",
      "02/09/2025 03:31:39 AM | 154 \n",
      "02/09/2025 03:31:39 AM | 155 \n",
      "02/09/2025 03:31:39 AM | 156 \n",
      "02/09/2025 03:31:39 AM | 157 \n",
      "02/09/2025 03:31:40 AM | 158 \n",
      "02/09/2025 03:31:40 AM | 159 \n",
      "02/09/2025 03:31:40 AM | 160 \n",
      "02/09/2025 03:31:41 AM | 161 \n",
      "02/09/2025 03:31:41 AM | 162 \n",
      "02/09/2025 03:31:41 AM | 163 \n",
      "02/09/2025 03:31:42 AM | 164 \n",
      "02/09/2025 03:31:42 AM | 165 \n",
      "02/09/2025 03:31:42 AM | 166 \n",
      "02/09/2025 03:31:43 AM | 167 \n",
      "02/09/2025 03:31:43 AM | 168 \n",
      "02/09/2025 03:31:43 AM | 169 \n",
      "02/09/2025 03:31:44 AM | 170 \n",
      "02/09/2025 03:31:44 AM | 171 \n",
      "02/09/2025 03:31:44 AM | 172 \n",
      "02/09/2025 03:31:45 AM | 173 \n",
      "02/09/2025 03:31:45 AM | 174 \n",
      "02/09/2025 03:31:45 AM | 175 \n",
      "02/09/2025 03:31:45 AM | 176 \n",
      "02/09/2025 03:31:46 AM | 177 \n",
      "02/09/2025 03:31:46 AM | 178 \n",
      "02/09/2025 03:31:46 AM | 179 \n",
      "02/09/2025 03:31:47 AM | 180 \n",
      "02/09/2025 03:31:47 AM | 181 \n",
      "02/09/2025 03:31:47 AM | 182 \n",
      "02/09/2025 03:31:48 AM | 183 \n",
      "02/09/2025 03:31:48 AM | 184 \n",
      "02/09/2025 03:31:48 AM | 185 \n",
      "02/09/2025 03:31:49 AM | 186 \n",
      "02/09/2025 03:31:49 AM | 187 \n",
      "02/09/2025 03:31:49 AM | 188 \n",
      "02/09/2025 03:31:50 AM | 189 \n",
      "02/09/2025 03:31:51 AM | 190 \n",
      "02/09/2025 03:31:51 AM | 191 \n",
      "02/09/2025 03:31:51 AM | 192 \n",
      "02/09/2025 03:31:52 AM | 193 \n",
      "02/09/2025 03:31:52 AM | 194 \n",
      "02/09/2025 03:31:52 AM | 195 \n",
      "02/09/2025 03:31:53 AM | 196 \n",
      "02/09/2025 03:31:53 AM | 197 \n",
      "02/09/2025 03:31:53 AM | 198 \n",
      "02/09/2025 03:31:54 AM | 199 \n",
      "02/09/2025 03:31:54 AM | 200 \n",
      "02/09/2025 03:31:54 AM | 201 \n",
      "02/09/2025 03:31:55 AM | 202 \n",
      "02/09/2025 03:31:55 AM | 203 \n",
      "02/09/2025 03:31:55 AM | 204 \n",
      "02/09/2025 03:31:56 AM | 205 \n",
      "02/09/2025 03:31:56 AM | 206 \n",
      "02/09/2025 03:31:56 AM | 207 \n",
      "02/09/2025 03:31:56 AM | 208 \n",
      "02/09/2025 03:31:57 AM | 209 \n",
      "02/09/2025 03:31:57 AM | 210 \n",
      "02/09/2025 03:31:58 AM | 211 \n",
      "02/09/2025 03:31:58 AM | 212 \n",
      "02/09/2025 03:31:58 AM | 213 \n",
      "02/09/2025 03:31:58 AM | 214 \n",
      "02/09/2025 03:31:59 AM | 215 \n",
      "02/09/2025 03:31:59 AM | 216 \n",
      "02/09/2025 03:31:59 AM | 217 \n",
      "02/09/2025 03:32:00 AM | 218 \n",
      "02/09/2025 03:32:00 AM | 219 \n",
      "02/09/2025 03:32:00 AM | 220 \n",
      "02/09/2025 03:32:01 AM | 221 \n",
      "02/09/2025 03:32:01 AM | 222 \n",
      "02/09/2025 03:32:01 AM | 223 \n",
      "02/09/2025 03:32:02 AM | 224 \n",
      "02/09/2025 03:32:02 AM | 225 \n",
      "02/09/2025 03:32:02 AM | 226 \n",
      "02/09/2025 03:32:03 AM | 227 \n",
      "02/09/2025 03:32:03 AM | 228 \n",
      "02/09/2025 03:32:03 AM | 229 \n",
      "02/09/2025 03:32:04 AM | 230 \n",
      "02/09/2025 03:32:04 AM | 231 \n",
      "02/09/2025 03:32:04 AM | 232 \n",
      "02/09/2025 03:32:05 AM | 233 \n",
      "02/09/2025 03:32:05 AM | 234 \n",
      "02/09/2025 03:32:05 AM | 235 \n",
      "02/09/2025 03:32:06 AM | 236 \n",
      "02/09/2025 03:32:06 AM | 237 \n",
      "02/09/2025 03:32:06 AM | 238 \n",
      "02/09/2025 03:32:07 AM | 239 \n",
      "02/09/2025 03:32:07 AM | 240 \n",
      "02/09/2025 03:32:07 AM | 241 \n",
      "02/09/2025 03:32:08 AM | 242 \n",
      "02/09/2025 03:32:08 AM | 243 \n",
      "02/09/2025 03:32:08 AM | 244 \n",
      "02/09/2025 03:32:10 AM | 245 \n",
      "02/09/2025 03:32:10 AM | 246 \n",
      "02/09/2025 03:32:10 AM | 247 \n",
      "02/09/2025 03:32:10 AM | 248 \n",
      "02/09/2025 03:32:11 AM | 249 \n",
      "02/09/2025 03:32:11 AM | 250 \n",
      "02/09/2025 03:32:11 AM | 251 \n",
      "02/09/2025 03:32:12 AM | 252 \n",
      "02/09/2025 03:32:12 AM | 253 \n",
      "02/09/2025 03:32:12 AM | 254 \n",
      "02/09/2025 03:32:13 AM | 255 \n"
     ]
    }
   ],
   "source": [
    "colors=['g','c']*5\n",
    "for i_roi, roi_idx in enumerate(roi_original_idx):\n",
    "    logging.info(i_roi)\n",
    "    cn = False\n",
    "    if roi_idx == target_roi_idx:\n",
    "        cn= True\n",
    "\n",
    "    roi_dff_bci_alignon_thr = dff_bci_alignon_thr[i_roi]\n",
    "    aligned_zaber_steps = zaber_steps-shifts.reshape(-1,1).astype(int)\n",
    "\n",
    "    fig=traces.plot_lick_spout_steps_dff(roi_dff_bci_alignon_thr,zaber_steps=aligned_zaber_steps,frames_before=frames_before,idx_threshold_change=idx_threshold_change,\n",
    "                                    subject_id=subject_id,session_name=session_name,i_roi=roi_idx,cn=cn,colors=colors,save=save, savepath='/scratch',save_format='jpg')\n",
    "    plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b1f423",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dff_signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ntrials \u001b[38;5;241m=\u001b[39m \u001b[43mdff_signal\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m max_act \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(dff_signal)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.555\u001b[39m\n\u001b[1;32m      3\u001b[0m dff_signal \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mint\u001b[39m(ntrials\u001b[38;5;241m*\u001b[39mmax_act),max_act)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'dff_signal' is not defined"
     ]
    }
   ],
   "source": [
    "ntrials = dff_signal.shape[0]\n",
    "max_act = np.nanmax(dff_signal)+0.555\n",
    "dff_signal + np.arange(0,int(ntrials*max_act),max_act).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9d574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(73.26482465956362)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntrials*max_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa83e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.4652964931912722)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ntrials*max_act)/ntrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.46529649,  2.93059299,  4.39588948,  5.86118597,\n",
       "        7.32648247,  8.79177896, 10.25707545, 11.72237195, 13.18766844,\n",
       "       14.65296493, 16.11826143, 17.58355792, 19.04885441, 20.5141509 ,\n",
       "       21.9794474 , 23.44474389, 24.91004038, 26.37533688, 27.84063337,\n",
       "       29.30592986, 30.77122636, 32.23652285, 33.70181934, 35.16711584,\n",
       "       36.63241233, 38.09770882, 39.56300532, 41.02830181, 42.4935983 ,\n",
       "       43.9588948 , 45.42419129, 46.88948778, 48.35478428, 49.82008077,\n",
       "       51.28537726, 52.75067375, 54.21597025, 55.68126674, 57.14656323,\n",
       "       58.61185973, 60.07715622, 61.54245271, 63.00774921, 64.4730457 ,\n",
       "       65.93834219, 67.40363869, 68.86893518, 70.33423167, 71.79952817,\n",
       "       73.26482466])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,ntrials*max_act,max_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65433866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
